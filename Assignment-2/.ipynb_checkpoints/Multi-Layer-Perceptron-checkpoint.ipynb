{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(dataset = \"training\", path = \".\"):\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        print(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        _, __, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows * cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def show(image):\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image.reshape(28, 28), cmap=mpl.cm.gray)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read('training', 'MNIST'); test = read('testing', 'MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = []\n",
    "lbl_train = []\n",
    "img_test = []\n",
    "lbl_test = []\n",
    "for temp in train:\n",
    "    img_train.append(temp[1])\n",
    "    lbl_train.append(temp[0])\n",
    "\n",
    "for temp in test:\n",
    "    img_test.append(temp[1])\n",
    "    lbl_test.append(temp[0])\n",
    "\n",
    "img_train = np.array(img_train)\n",
    "lbl_train = np.array(lbl_train)\n",
    "img_test = np.array(img_test)\n",
    "lbl_test = np.array(lbl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "show(img_test[11])\n",
    "print(lbl_test[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multilayer feedforward neural network\n",
    "This section contains the code for MLFFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        z[z < 0] = 0\n",
    "        return z\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        z[z < 0] = 0\n",
    "        z[z > 0] = 1\n",
    "        return z\n",
    "        \n",
    "class Sigmoid:\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        return Sigmoid.activation(z) * (1 - Sigmoid.activation(z))\n",
    "    \n",
    "class MSE:\n",
    "    def __init__(self, activation_fn=None):\n",
    "        self.activation_fn = activation_fn\n",
    "            \n",
    "    def activation(self, z):\n",
    "        return self.activation_fn.activation(z)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(y_true, y_pred):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def derivative(y_true, y_pred):\n",
    "        return y_pred - y_true\n",
    "\n",
    "    def delta(self, y_true, y_pred):\n",
    "        return self.derivative(y_true, y_pred) * self.activation_fn.derivative(y_pred)\n",
    "    \n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, dimensions, activation_fns):\n",
    "        self.n_layers = len(dimensions)\n",
    "        self.loss = None\n",
    "        self.learning_rate = None\n",
    "        self.weights = {}\n",
    "        self.bais = {}\n",
    "        self.activations = {}\n",
    "        for i in range(self.n_layers - 1):\n",
    "            self.weights[i + 1] = np.random.randn(dimensions[i], dimensions[i + 1]) / np.sqrt(dimensions[i])\n",
    "            self.bais[i + 1] = np.zeros(dimensions[i + 1])\n",
    "            self.activations[i + 2] = activation_fns[i]\n",
    "            \n",
    "    def feed_forward(self, x):\n",
    "        z = {}\n",
    "        activated = {1: x}\n",
    "        for i in range(1, self.n_layers):\n",
    "            z[i + 1] = np.dot(activated[i], self.weights[i]) + self.bais[i]\n",
    "            activated[i + 1] = self.activations[i + 1].activation(z[i + 1])\n",
    "        return z, activated\n",
    "    \n",
    "    def back_propagation(self, z, a, y_true):\n",
    "        delta = self.loss.delta(y_true, a[self.n_layers])\n",
    "        partial_derivative = np.dot(a[self.n_layers - 1].T, delta)\n",
    "\n",
    "        update_params = {\n",
    "            self.n_layers - 1: (partial_derivative, delta)\n",
    "        }\n",
    "\n",
    "        for i in reversed(range(2, self.n_layers)):\n",
    "            delta = np.dot(delta, self.weights[i].T) * self.activations[i].derivative(z[i])\n",
    "            partial_derivative = np.dot(a[i - 1].T, delta)\n",
    "            update_params[i - 1] = (partial_derivative, delta)\n",
    "\n",
    "        for key, values in update_params.items():\n",
    "            self.update_fn(key, values[0], values[1])\n",
    "        \n",
    "    def update_fn(self, key, partial_derivative, delta):\n",
    "        self.weights[key] -= self.learning_rate * partial_derivative\n",
    "        self.bais[key] -= self.learning_rate * np.mean(delta, 0)\n",
    "\n",
    "    def learn(self, x, y_true, loss, epochs, batch_size, learning_rate):\n",
    "        self.loss = loss(self.activations[self.n_layers])\n",
    "        self.learning_rate = learning_rate\n",
    "        for i in range(epochs):\n",
    "            seed = np.arange(x.shape[0])\n",
    "            np.random.shuffle(seed)\n",
    "            x_ = x[seed]\n",
    "            y_ = y_true[seed]\n",
    "            for j in range(x.shape[0] // batch_size):\n",
    "                k = j * batch_size\n",
    "                l = (j + 1) * batch_size\n",
    "                z, a = self.feed_forward(x_[k:l])\n",
    "                self.back_propagation(z, a, y_[k:l])\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                _, a = self.feed_forward(x)\n",
    "                print(\"Epoch\", i + 1, \"Loss:\", self.loss.loss(y_true, a[self.n_layers]))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        _, a = self.feed_forward(x)\n",
    "        return a[self.n_layers]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1 = NeuralNetwork([784, 30, 10], (Sigmoid, Sigmoid))\n",
    "img_train.shape\n",
    "y_ = np.eye(10)[lbl_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Loss: 0.025376669371423168\n",
      "Epoch 200 Loss: 0.024179243782364673\n",
      "Epoch 300 Loss: 0.024385905212599285\n",
      "Epoch 400 Loss: 0.023219991527876165\n",
      "Epoch 500 Loss: 0.02131914413413396\n",
      "Epoch 600 Loss: 0.02090686855296405\n",
      "Epoch 700 Loss: 0.020916652708744408\n",
      "Epoch 800 Loss: 0.02174889373512917\n",
      "Epoch 900 Loss: 0.02033294603059983\n",
      "Epoch 1000 Loss: 0.021485046756930023\n"
     ]
    }
   ],
   "source": [
    "nn1.learn(img_train, y_, MSE, 1000, 128, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predictions = np.argmax(nn1.predict(img_test), axis=0)\n",
    "y__ = np.eye(10)[lbl_test]\n",
    "labels = np.argmax(lbl_test, axis=0)\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(nn1.predict(img_test), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 944    0   36    5    3   21   34    3   17   12]\n",
      " [   0 1076    6    8    6    1    2   10   16    6]\n",
      " [   4    4  811   34    5    6    2   14    8    3]\n",
      " [   2   28   87  763    0   22    2   39   34    3]\n",
      " [   0    0   15    0  827    6   30    8    5   17]\n",
      " [   1    1    3  156    2  730   22    0   39   17]\n",
      " [  20    3   30    0   12   33  851    0   22    1]\n",
      " [   4    3    9   13    0    4    3  920   12   10]\n",
      " [   4   20   26   17    4   49   11    0  774    4]\n",
      " [   1    0    9   14  123   20    1   34   47  936]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.88      0.92      1075\n",
      "          1       0.95      0.95      0.95      1131\n",
      "          2       0.79      0.91      0.84       891\n",
      "          3       0.76      0.78      0.77       980\n",
      "          4       0.84      0.91      0.88       908\n",
      "          5       0.82      0.75      0.78       971\n",
      "          6       0.89      0.88      0.88       972\n",
      "          7       0.89      0.94      0.92       978\n",
      "          8       0.79      0.85      0.82       909\n",
      "          9       0.93      0.79      0.85      1185\n",
      "\n",
      "avg / total       0.87      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(predictions, lbl_test))\n",
    "print(classification_report(predictions, lbl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
