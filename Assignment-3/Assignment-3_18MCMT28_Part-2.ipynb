{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Wine Quality\n",
    "\n",
    "## About the problem\n",
    "his datasets is related to red  and white variants of the Portuguese \"Vinho Verde\" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n",
    "\n",
    "The datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are much more normal wines than excellent or poor ones).\n",
    "\n",
    "This dataset is also available from the UCI machine learning repository, https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "\n",
    "\n",
    "\n",
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-28 22:46:28--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84199 (82K) [text/csv]\n",
      "Saving to: ‘wine-red.csv’\n",
      "\n",
      "wine-red.csv        100%[===================>]  82.23K  66.9KB/s    in 1.2s    \n",
      "\n",
      "2018-10-28 22:46:30 (66.9 KB/s) - ‘wine-red.csv’ saved [84199/84199]\n",
      "\n",
      "--2018-10-28 22:46:30--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 264426 (258K) [text/csv]\n",
      "Saving to: ‘wine-white.csv’\n",
      "\n",
      "wine-white.csv      100%[===================>] 258.23K   122KB/s    in 2.1s    \n",
      "\n",
      "2018-10-28 22:46:34 (122 KB/s) - ‘wine-white.csv’ saved [264426/264426]\n",
      "\n",
      "wine-red.csv  wine-white.csv\n"
     ]
    }
   ],
   "source": [
    "!wget -O wine-red.csv https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
    "!wget -O wine-white.csv https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
    "!ls *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "with open('wine-red.csv') as fp:\n",
    "    fp.readline()\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        train.append(list(map(float, line.strip().split(';'))))\n",
    "        line = fp.readline()\n",
    "with open('wine-white.csv') as fp:\n",
    "    fp.readline()\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        train.append(list(map(float, line.strip().split(';'))))\n",
    "        line = fp.readline()\n",
    "train = np.array(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train[:, [-1]]\n",
    "test = test.reshape(-1)\n",
    "test = test > 6\n",
    "test = test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for K = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=6)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "1.000 (+/-0.000) for {'C': 1, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 10, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 100, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 1000, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 10000, 'kernel': 'linear'}\n",
      "0.918 (+/-0.002) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.401 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.995 (+/-0.005) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.970 (+/-0.010) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.002) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.004) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.002) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.004) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.002) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1048\n",
      "          1       1.00      1.00      1.00       252\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1300\n",
      "\n",
      "\n",
      "Final accuracy = 1.0\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "1.000 (+/-0.000) for {'C': 1, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 10, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 100, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 1000, 'kernel': 'linear'}\n",
      "1.000 (+/-0.000) for {'C': 10000, 'kernel': 'linear'}\n",
      "0.599 (+/-0.013) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.984 (+/-0.011) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.870 (+/-0.046) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.004) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "1.000 (+/-0.002) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.005) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.002) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.005) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.002) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1048\n",
      "          1       1.00      1.00      1.00       252\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1300\n",
      "\n",
      "\n",
      "Final accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [\n",
    "  {'C': [1, 10, 100, 1000, 10000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000, 10000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "scores_list = ['precision', 'recall']\n",
    "for score in scores_list:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"Final accuracy =\", accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that for $C=1$ and for kernel linear, the model performs best with $100\\%$ accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "clf1 = SVC(kernel='linear', C=C).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support Vectors = 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of support Vectors =\", len(clf1.support_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of suppport vectors for each class: [9 3]\n",
      "The margin support vectors = 10\n",
      "The non-margin support vectors = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of suppport vectors for each class:\", clf1.n_support_ )\n",
    "alphas = np.absolute(clf1.dual_coef_)\n",
    "msv = np.count_nonzero(alphas == C)\n",
    "print(\"The margin support vectors =\", clf1.dual_coef_.shape[1] - msv)\n",
    "print(\"The non-margin support vectors =\", msv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E\\left [ Out\\_Sample\\_Error \\right ] \\leq \\frac{E\\left [ Number\\_of\\_Support\\_Vectors \\right ]}{N - 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The condition is false\n"
     ]
    }
   ],
   "source": [
    "mean = np.array(means).mean()\n",
    "if mean < len(clf1.support_) / (X_train.shape[0] - 1):\n",
    "    print(\"The condition holds true\")\n",
    "else:\n",
    "    print(\"The condition is false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1048\n",
      "          1       1.00      1.00      1.00       252\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=6)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search to find the best hyper-parameters with Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sai/.virtualenvs/Tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [\n",
    "  {'C': [1, 10, 100, 1000, 10000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000, 10000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "scores_list = ['precision', 'recall']\n",
    "for score in scores_list:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"Final accuracy =\", accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that for $C=1$ and for kernel linear, the model performs best with $100\\%$ accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "clf2 = SVC(kernel='linear', C=C).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of support Vectors =\", len(clf2.support_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of suppport vectors for each class:\", clf1.n_support_ )\n",
    "alphas = np.absolute(clf1.dual_coef_)\n",
    "msv = np.count_nonzero(alphas == C)\n",
    "print(\"The margin support vectors =\", clf1.dual_coef_.shape[1] - msv)\n",
    "print(\"The non-margin support vectors =\", msv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E\\left [ Out\\_Sample\\_Error \\right ] \\leq \\frac{E\\left [ Number\\_of\\_Support\\_Vectors \\right ]}{N - 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array(means).mean()\n",
    "if mean < len(clf1.support_) / (X_train.shape[0] - 1):\n",
    "    print(\"The condition holds true\")\n",
    "else:\n",
    "    print(\"The condition is false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "1. In both the cases for $k=6$ and $k=2$, we get a cent percent accuracy.\n",
    "2. Due to the less number of dimesnions there maybe a chance of over-fitting\n",
    "3. The generalisation error condition does not satisfy for both the K values as these models make no error\n",
    "4. The number of support vectors learned are very less\n",
    "5. Since, the support vectors are less, we in general can expect less generalisation error.\n",
    "6. With RBF kernel a higher C value seems to perform better\n",
    "7. With linear kernel, there is not much change with the change in C value\n",
    "8. The mean accuracy across folds is almost always more than $90\\%$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
